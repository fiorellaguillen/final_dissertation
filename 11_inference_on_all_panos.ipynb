{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e61ceb",
   "metadata": {},
   "source": [
    "## Inference using Deeplabv3+ V6 on full Mapillary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624fcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e5e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'results.csv' saved\n"
     ]
    }
   ],
   "source": [
    "#Configuration\n",
    "device = torch.device(\"cuda\")\n",
    "model_path = \"../best_deeplabmodels/V6_cmp_ft_encoder_l34.pth\"\n",
    "image_dir = \"../panos/cropped_panos\"\n",
    "output_dir = \"../inference/results_model_v6/images\"\n",
    "results_dir = \"../inference/results_model_v6/results.csv\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "num_classes = 4\n",
    "ignore_class = 0\n",
    "image_size = (512, 1024)\n",
    "\n",
    "#Transform\n",
    "transform = T.Compose([\n",
    "    T.Resize(image_size),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Load model\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet101\",       \n",
    "    encoder_weights=\"imagenet\",  \n",
    "    in_channels=3,                  \n",
    "    classes=num_classes         \n",
    ")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)) #Load best model (V6)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "#Process all Mapillary images\n",
    "results = []\n",
    "all_filenames = sorted(os.listdir(image_dir))\n",
    "\n",
    "for filename in all_filenames:\n",
    "    #Read image\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    #Run inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred = torch.argmax(output.squeeze(), dim=0).cpu().numpy()\n",
    "\n",
    "    #Extract IDs\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    edge_id, pano_id = base.split(\"_\", 1)\n",
    "\n",
    "    #Calculate percentage of pixels per class, ignore class 0\n",
    "    total_pixels = (pred != ignore_class).sum()\n",
    "    percentages = []\n",
    "    for cls in range(1, num_classes):\n",
    "        class_pixels = (pred == cls).sum()\n",
    "        pct = (class_pixels / total_pixels * 100) if total_pixels > 0 else 0.0\n",
    "        percentages.append(round(pct, 4))\n",
    "\n",
    "    #Save image with masks overlays\n",
    "    if filename in all_filenames:\n",
    "\n",
    "        #Define colors for each mask class\n",
    "        colors = {\n",
    "            0: (0, 0, 0, 0),          # transparent for ignore_class\n",
    "            1: (0, 0, 255, 100),      # semi-transparent blue for background\n",
    "            2: (0, 255, 0, 100),      # semi-transparent green for porosity\n",
    "            3: (255, 0, 0, 100)       # semi-transparent red for wall\n",
    "        }\n",
    "\n",
    "        # Resize prediction to match original size\n",
    "        pred_resized = Image.fromarray(pred.astype(np.uint8)).resize(img.size, resample=Image.NEAREST)\n",
    "        pred_np = np.array(pred_resized)\n",
    "\n",
    "        # Create empty RGBA image for mask\n",
    "        mask_rgba = Image.new(\"RGBA\", img.size, (0, 0, 0, 0))\n",
    "        mask_pixels = mask_rgba.load()\n",
    "\n",
    "        # Assign colors per pixel according to class\n",
    "        for y in range(pred_np.shape[0]):\n",
    "            for x in range(pred_np.shape[1]):\n",
    "                cls = pred_np[y, x]\n",
    "                mask_pixels[x, y] = colors.get(cls, (0, 0, 0, 0))\n",
    "\n",
    "        # Convert original image to RGBA\n",
    "        img_rgba = img.convert(\"RGBA\")\n",
    "\n",
    "        # Overlay mask with transparency\n",
    "        overlayed = Image.alpha_composite(img_rgba, mask_rgba)\n",
    "\n",
    "        # Save overlayed image\n",
    "        overlayed.save(os.path.join(output_dir, f\"{base}_overlay.png\"))\n",
    "\n",
    "    # Add to results\n",
    "    results.append({\n",
    "        \"edge_id\": edge_id,\n",
    "        \"pano_id\": pano_id,\n",
    "        \"pct_background\": percentages[0], # Class 1\n",
    "        \"pct_porosity\": percentages[1],   # Class 2\n",
    "        \"pct_wall\": percentages[2],       # Class 3\n",
    "    })\n",
    "\n",
    "# Create final dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df.to_csv(results_dir, index=False)\n",
    "print(\"'results.csv' saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "porosity_env_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
